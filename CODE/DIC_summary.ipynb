{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "92064ef8-37ff-454b-ba6b-69c92444cafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DIC CSV → per-frame summaries (tailored to your headers)\n",
    "\n",
    "\n",
    "from pathlib import Path\n",
    "import re, os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "try:\n",
    "    from tqdm import tqdm\n",
    "except Exception:\n",
    "    tqdm = lambda x, **k: x  # no-op if tqdm is absent\n",
    "\n",
    "# -------- PATHS --------\n",
    "DIC_ROOT    = Path(\"Dissertation/Hari Export\")             # folder with all DIC CSVs (recursive)\n",
    "OUT_DIR     = Path(\"./outputs\"); OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "OUT_SUMMARY = OUT_DIR / \"dic_summary.csv\"\n",
    "\n",
    "# -------- EXACT COLUMN NAMES (as seen in your CSV) --------\n",
    "COL_U    = \"disp.Horizontal Displacement U [Pixel]\"\n",
    "COL_V    = \"disp.Vertical Displacement V [Pixel]\"\n",
    "COL_EXX  = \"strain.Strain-local frame: Exx [ ]\"\n",
    "COL_EYY  = \"strain.Strain-local frame: Eyy [ ]\"\n",
    "COL_EXY  = \"strain.Strain-local frame: Exy [ ]\"\n",
    "COL_VM   = \"strain.Von Mises Equivalent Strain [ ]\"\n",
    "COL_FRAMEIDX = \"ext.Current Image [#]\"   # optional\n",
    "\n",
    "# -------- HELPERS --------\n",
    "def frame_id_from_path(p: Path) -> str:\n",
    "    \"\"\"Strip .csv and any trailing .tif/.tiff from filename to get a frame_id like '20cm_0071'.\"\"\"\n",
    "    name = p.name\n",
    "    if name.lower().endswith(\".csv\"):  name = name[:-4]\n",
    "    name = re.sub(r\"\\.(tif|tiff)$\", \"\", name, flags=re.IGNORECASE)\n",
    "    return name\n",
    "\n",
    "def nanpercentile(a, q):\n",
    "    a = np.asarray(a)\n",
    "    if a.size == 0: return np.nan\n",
    "    a = a[np.isfinite(a)]\n",
    "    if a.size == 0: return np.nan\n",
    "    return float(np.percentile(a, q))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "96be226a-25a7-4c76-9dd7-97d8fcb91eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarise_dic_csv(csv_path: Path):\n",
    "    \"\"\"\n",
    "    Reduce one frame CSV into a few summaries:\n",
    "      - n_subsets\n",
    "      - mean_disp_px, p95_disp_px (from U,V)\n",
    "      - mean_vmises\n",
    "      - mean_exx, mean_eyy, mean_exy  (optional but cheap)\n",
    "    Returns a dict (or None if unreadable).\n",
    "    \"\"\"\n",
    "    usecols = [c for c in [COL_U, COL_V, COL_EXX, COL_EYY, COL_EXY, COL_VM, COL_FRAMEIDX] if c is not None]\n",
    "    try:\n",
    "        df = pd.read_csv(csv_path, usecols=usecols, dtype=np.float32, engine=\"c\", low_memory=False)\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] read_csv failed: {csv_path} -> {e}\")\n",
    "        return None\n",
    "\n",
    "    out = {\n",
    "        \"frame_id\": frame_id_from_path(csv_path),\n",
    "        \"n_subsets\": int(len(df)),\n",
    "        \"mean_disp_px\": np.nan,\n",
    "        \"p95_disp_px\":  np.nan,\n",
    "        \"mean_vmises\":  np.nan,\n",
    "        \"mean_exx\":     np.nan,\n",
    "        \"mean_eyy\":     np.nan,\n",
    "        \"mean_exy\":     np.nan,\n",
    "    }\n",
    "\n",
    "    # --- Displacement magnitude ---\n",
    "    if (COL_U in df.columns) and (COL_V in df.columns):\n",
    "        U = df[COL_U].to_numpy()\n",
    "        V = df[COL_V].to_numpy()\n",
    "        disp = np.sqrt(U*U + V*V)\n",
    "        disp = disp[np.isfinite(disp)]\n",
    "        if disp.size:\n",
    "            out[\"mean_disp_px\"] = float(np.nanmean(disp))\n",
    "            out[\"p95_disp_px\"]  = nanpercentile(disp, 95)\n",
    "\n",
    "    # --- Von Mises strain ---\n",
    "    if COL_VM in df.columns:\n",
    "        vm = df[COL_VM].to_numpy()\n",
    "        vm = vm[np.isfinite(vm)]\n",
    "        if vm.size:\n",
    "            out[\"mean_vmises\"] = float(np.nanmean(vm))\n",
    "\n",
    "    # --- Strain tensor components (optional means) ---\n",
    "    for col, key in [(COL_EXX, \"mean_exx\"), (COL_EYY, \"mean_eyy\"), (COL_EXY, \"mean_exy\")]:\n",
    "        if col in df.columns:\n",
    "            vals = df[col].to_numpy()\n",
    "            vals = vals[np.isfinite(vals)]\n",
    "            if vals.size:\n",
    "                out[key] = float(np.nanmean(vals))\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e8654097-f082-48a3-aef4-577855293a9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1693 CSV files under /home/ubuntu/Dissertation/Hari Export\n",
      "Using 3 workers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summarising: 100%|██████████████████████████| 1693/1693 [01:27<00:00, 19.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 1693 rows to /home/ubuntu/outputs/dic_summary.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frame_id</th>\n",
       "      <th>n_subsets</th>\n",
       "      <th>mean_disp_px</th>\n",
       "      <th>p95_disp_px</th>\n",
       "      <th>mean_vmises</th>\n",
       "      <th>mean_exx</th>\n",
       "      <th>mean_eyy</th>\n",
       "      <th>mean_exy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0cm_0000</td>\n",
       "      <td>48884</td>\n",
       "      <td>0.067775</td>\n",
       "      <td>0.081151</td>\n",
       "      <td>0.000245</td>\n",
       "      <td>6.978449e-07</td>\n",
       "      <td>7.720270e-06</td>\n",
       "      <td>0.000009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0cm_0001</td>\n",
       "      <td>48884</td>\n",
       "      <td>0.076478</td>\n",
       "      <td>0.106096</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>-1.672498e-05</td>\n",
       "      <td>-5.284778e-06</td>\n",
       "      <td>-0.000020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0cm_0002</td>\n",
       "      <td>48884</td>\n",
       "      <td>0.098983</td>\n",
       "      <td>0.121090</td>\n",
       "      <td>0.000226</td>\n",
       "      <td>6.927095e-06</td>\n",
       "      <td>2.830703e-06</td>\n",
       "      <td>0.000009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0cm_0003</td>\n",
       "      <td>48884</td>\n",
       "      <td>0.129337</td>\n",
       "      <td>0.163201</td>\n",
       "      <td>0.000220</td>\n",
       "      <td>-5.245639e-06</td>\n",
       "      <td>-2.995358e-05</td>\n",
       "      <td>-0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0cm_0004</td>\n",
       "      <td>48884</td>\n",
       "      <td>0.106204</td>\n",
       "      <td>0.157112</td>\n",
       "      <td>0.000240</td>\n",
       "      <td>2.668238e-05</td>\n",
       "      <td>9.203127e-07</td>\n",
       "      <td>-0.000027</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   frame_id  n_subsets  mean_disp_px  p95_disp_px  mean_vmises      mean_exx  \\\n",
       "0  0cm_0000      48884      0.067775     0.081151     0.000245  6.978449e-07   \n",
       "1  0cm_0001      48884      0.076478     0.106096     0.000202 -1.672498e-05   \n",
       "2  0cm_0002      48884      0.098983     0.121090     0.000226  6.927095e-06   \n",
       "3  0cm_0003      48884      0.129337     0.163201     0.000220 -5.245639e-06   \n",
       "4  0cm_0004      48884      0.106204     0.157112     0.000240  2.668238e-05   \n",
       "\n",
       "       mean_eyy  mean_exy  \n",
       "0  7.720270e-06  0.000009  \n",
       "1 -5.284778e-06 -0.000020  \n",
       "2  2.830703e-06  0.000009  \n",
       "3 -2.995358e-05 -0.000018  \n",
       "4  9.203127e-07 -0.000027  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Find all CSVs under Hari_Export (recursively)\n",
    "# Discover CSVs\n",
    "csv_files = sorted(DIC_ROOT.rglob(\"*.csv\"))\n",
    "print(f\"Found {len(csv_files)} CSV files under {DIC_ROOT.resolve()}\")\n",
    "\n",
    "# Parallel process files\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "results = []\n",
    "num_workers = max(1, (os.cpu_count() or 2) - 1)\n",
    "print(f\"Using {num_workers} workers\")\n",
    "\n",
    "with ProcessPoolExecutor(max_workers=num_workers) as ex:\n",
    "    futs = {ex.submit(summarise_dic_csv, p): p for p in csv_files}\n",
    "    for fut in tqdm(as_completed(futs), total=len(futs), desc=\"Summarising\"):\n",
    "        rec = fut.result()\n",
    "        if rec is not None:\n",
    "            results.append(rec)\n",
    "\n",
    "df_dic = pd.DataFrame(results)\n",
    "if df_dic.empty:\n",
    "    raise RuntimeError(\"No summaries produced — check CSV format/paths.\")\n",
    "\n",
    "# Sort and save\n",
    "df_dic = df_dic.sort_values(\"frame_id\").reset_index(drop=True)\n",
    "df_dic.to_csv(OUT_SUMMARY, index=False)\n",
    "print(f\"Wrote {len(df_dic)} rows to {OUT_SUMMARY.resolve()}\")\n",
    "display(df_dic.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0747da-ab47-4c28-8d49-f5f58957707f",
   "metadata": {},
   "source": [
    "## Load DIC + model scores, standardise IDs, and join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aedf9d70-81bc-472a-9066-24c5206b9366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joined frames: total=249, haze_subset=249\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>split</th>\n",
       "      <th>frame_id</th>\n",
       "      <th>class</th>\n",
       "      <th>n_tiles</th>\n",
       "      <th>pbar</th>\n",
       "      <th>class_name</th>\n",
       "      <th>n_subsets</th>\n",
       "      <th>mean_disp_px</th>\n",
       "      <th>p95_disp_px</th>\n",
       "      <th>mean_vmises</th>\n",
       "      <th>mean_exx</th>\n",
       "      <th>mean_eyy</th>\n",
       "      <th>mean_exy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test</td>\n",
       "      <td>0cm_0020</td>\n",
       "      <td>haze</td>\n",
       "      <td>4</td>\n",
       "      <td>0.999793</td>\n",
       "      <td>haze</td>\n",
       "      <td>48884</td>\n",
       "      <td>0.044733</td>\n",
       "      <td>0.062678</td>\n",
       "      <td>0.000310</td>\n",
       "      <td>-1.231292e-05</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test</td>\n",
       "      <td>0cm_0035</td>\n",
       "      <td>haze</td>\n",
       "      <td>4</td>\n",
       "      <td>0.998599</td>\n",
       "      <td>haze</td>\n",
       "      <td>48884</td>\n",
       "      <td>0.084901</td>\n",
       "      <td>0.099869</td>\n",
       "      <td>0.000340</td>\n",
       "      <td>-2.089861e-07</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>-0.000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test</td>\n",
       "      <td>0cm_0042</td>\n",
       "      <td>haze</td>\n",
       "      <td>4</td>\n",
       "      <td>0.999888</td>\n",
       "      <td>haze</td>\n",
       "      <td>48884</td>\n",
       "      <td>0.055209</td>\n",
       "      <td>0.083793</td>\n",
       "      <td>0.000325</td>\n",
       "      <td>1.721081e-05</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test</td>\n",
       "      <td>0cm_0049</td>\n",
       "      <td>haze</td>\n",
       "      <td>4</td>\n",
       "      <td>0.998309</td>\n",
       "      <td>haze</td>\n",
       "      <td>48884</td>\n",
       "      <td>0.054215</td>\n",
       "      <td>0.090791</td>\n",
       "      <td>0.000435</td>\n",
       "      <td>-3.094885e-05</td>\n",
       "      <td>-0.000008</td>\n",
       "      <td>-0.000020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test</td>\n",
       "      <td>0cm_0050</td>\n",
       "      <td>haze</td>\n",
       "      <td>4</td>\n",
       "      <td>0.998402</td>\n",
       "      <td>haze</td>\n",
       "      <td>48884</td>\n",
       "      <td>0.100656</td>\n",
       "      <td>0.161727</td>\n",
       "      <td>0.000354</td>\n",
       "      <td>-6.522970e-05</td>\n",
       "      <td>-0.000026</td>\n",
       "      <td>0.000013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  split  frame_id class  n_tiles      pbar class_name  n_subsets  \\\n",
       "0  test  0cm_0020  haze        4  0.999793       haze      48884   \n",
       "1  test  0cm_0035  haze        4  0.998599       haze      48884   \n",
       "2  test  0cm_0042  haze        4  0.999888       haze      48884   \n",
       "3  test  0cm_0049  haze        4  0.998309       haze      48884   \n",
       "4  test  0cm_0050  haze        4  0.998402       haze      48884   \n",
       "\n",
       "   mean_disp_px  p95_disp_px  mean_vmises      mean_exx  mean_eyy  mean_exy  \n",
       "0      0.044733     0.062678     0.000310 -1.231292e-05  0.000004  0.000002  \n",
       "1      0.084901     0.099869     0.000340 -2.089861e-07  0.000009 -0.000005  \n",
       "2      0.055209     0.083793     0.000325  1.721081e-05  0.000012  0.000018  \n",
       "3      0.054215     0.090791     0.000435 -3.094885e-05 -0.000008 -0.000020  \n",
       "4      0.100656     0.161727     0.000354 -6.522970e-05 -0.000026  0.000013  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- CELL 1: load + normalise + join (drop-in replacement) ---\n",
    "from pathlib import Path\n",
    "import pandas as pd, numpy as np, re\n",
    "\n",
    "OUT_DIR = Path(\"outputs\")\n",
    "FIGS_DIR = OUT_DIR / \"figs\"; FIGS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "DIC_CSV   = OUT_DIR / \"dic_summary.csv\"     # DIC reduction\n",
    "PBAR_CSV  = OUT_DIR / \"pbar_test.csv\"       # non-overlap frame scores\n",
    "\n",
    "THR = 0.882  # your current Youden threshold\n",
    "\n",
    "df_d = pd.read_csv(DIC_CSV)\n",
    "df_p = pd.read_csv(PBAR_CSV)\n",
    "\n",
    "def _norm_id(s):\n",
    "    s = str(s)\n",
    "    return re.sub(r\"\\.(csv|tif|tiff)$\", \"\", s, flags=re.IGNORECASE)\n",
    "\n",
    "for col in [\"frame_id\"]:\n",
    "    if col in df_d: df_d[col] = df_d[col].map(_norm_id)\n",
    "    if col in df_p: df_p[col] = df_p[col].map(_norm_id)\n",
    "\n",
    "# map class to string (if present)\n",
    "if \"class\" in df_p.columns:\n",
    "    def _to_name(v):\n",
    "        try:\n",
    "            return \"haze\" if int(v)==1 else \"nonhaze\"\n",
    "        except Exception:\n",
    "            return \"haze\" if \"haze\" in str(v).lower() and \"non\" not in str(v).lower() else \"nonhaze\"\n",
    "    df_p[\"class_name\"] = df_p[\"class\"].map(_to_name)\n",
    "else:\n",
    "    df_p[\"class_name\"] = \"unknown\"\n",
    "\n",
    "dfj = df_p.merge(df_d, on=\"frame_id\", how=\"inner\")\n",
    "dfj_haze = dfj[dfj[\"class_name\"]==\"haze\"].copy() if \"class_name\" in dfj.columns else dfj.copy()\n",
    "\n",
    "print(f\"Joined frames: total={len(dfj)}, haze_subset={len(dfj_haze)}\")\n",
    "dfj_haze.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b673b6b4-b522-41b0-bf03-e9eb1d8cccea",
   "metadata": {},
   "source": [
    "## Compute headline stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3c0f7298-44aa-429d-a7db-92676afb8596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   n_frames_joined  threshold_T  coverage_at_T  spearman_rho_pbar_vs_p95disp  \\\n",
      "0              249        0.882          0.996                        -0.219   \n",
      "\n",
      "   p_value_p95disp  spearman_rho_pbar_vs_vmises  p_value_vmises  topk_k  \\\n",
      "0            0.001                        0.293             0.0      24   \n",
      "\n",
      "   topk_overlap_count  topk_jaccard  \n",
      "0                   0           0.0  \n",
      "Saved: outputs/dic_x_model_summary.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "def spearman_rho(x, y):\n",
    "    try:\n",
    "        from scipy.stats import spearmanr\n",
    "        rho, p = spearmanr(x, y, nan_policy='omit')\n",
    "        return float(rho), float(p)\n",
    "    except Exception:\n",
    "        # fallback: Pearson of ranks\n",
    "        xr = pd.Series(x).rank().to_numpy()\n",
    "        yr = pd.Series(y).rank().to_numpy()\n",
    "        rho = np.corrcoef(xr, yr)[0,1]\n",
    "        return float(rho), np.nan\n",
    "\n",
    "def coverage_at_T(p, T):\n",
    "    p = np.asarray(p)\n",
    "    return float((p >= T).mean()) if p.size else np.nan\n",
    "\n",
    "# Choose the DIC intensity measures to compare with pbar\n",
    "y_pbar  = dfj_haze[\"pbar\"].to_numpy()\n",
    "x_p95   = dfj_haze[\"p95_disp_px\"].to_numpy()     # “worst pockets” of motion\n",
    "x_vm    = dfj_haze.get(\"mean_vmises\", pd.Series(dtype=float)).to_numpy()  # unitless strain\n",
    "\n",
    "# Coverage\n",
    "covT = coverage_at_T(y_pbar, THR)\n",
    "\n",
    "# Spearman correlations\n",
    "rho_p95, p_p95 = spearman_rho(x_p95, y_pbar)\n",
    "rho_vm,  p_vm  = spearman_rho(x_vm,  y_pbar) if len(x_vm)>0 else (np.nan, np.nan)\n",
    "\n",
    "# Optional: top-k overlap (k = max(1, 10% of set))\n",
    "N = len(dfj_haze)\n",
    "k = max(1, int(0.10 * N))\n",
    "idx_top_pbar = np.argsort(-y_pbar)[:k]\n",
    "idx_top_p95  = np.argsort(-x_p95)[:k]\n",
    "top_overlap  = len(set(idx_top_pbar).intersection(set(idx_top_p95)))\n",
    "top_jaccard  = top_overlap / float(2*k - top_overlap) if k>0 else np.nan\n",
    "\n",
    "# Save a tiny summary CSV for LaTeX\n",
    "summary = pd.DataFrame([{\n",
    "    \"n_frames_joined\": N,\n",
    "    \"threshold_T\": THR,\n",
    "    \"coverage_at_T\": covT,\n",
    "    \"spearman_rho_pbar_vs_p95disp\": rho_p95,\n",
    "    \"p_value_p95disp\": p_p95,\n",
    "    \"spearman_rho_pbar_vs_vmises\": rho_vm,\n",
    "    \"p_value_vmises\": p_vm,\n",
    "    \"topk_k\": k,\n",
    "    \"topk_overlap_count\": top_overlap,\n",
    "    \"topk_jaccard\": top_jaccard\n",
    "}])\n",
    "summary_path = OUT_DIR / \"dic_x_model_summary.csv\"\n",
    "summary.to_csv(summary_path, index=False)\n",
    "\n",
    "print(summary.round(3))\n",
    "print(f\"Saved: {summary_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503d3351-f357-438d-834d-73ee14c6eec6",
   "metadata": {},
   "source": [
    "## Plots: (1) scatter p95_disp vs pbar; (2) coverage by quartiles \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c6dfc26e-48ed-46f8-928c-0db6fb49537f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: outputs/figs/dic_vs_pbar_scatter.png\n",
      "Saved: outputs/figs/coverage_by_p95_quartile.png outputs/figs/pbar_vs_dic_deciles.png\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 1) Scatter with threshold line and rho annotation\n",
    "fig, ax = plt.subplots(figsize=(6,4))\n",
    "ax.scatter(dfj_haze[\"p95_disp_px\"], dfj_haze[\"pbar\"], s=16, alpha=0.6, edgecolors='k', linewidths=0.2)\n",
    "ax.axhline(THR, linestyle='--', linewidth=1.0, label=f'Threshold T={THR:.3f}')\n",
    "ax.set_xlabel(\"Per-frame displacement (95th percentile, pixels)\")\n",
    "ax.set_ylabel(\"Classifier probability (0–1)\")\n",
    "ax.set_title(\"DIC vs classifier score (joined haze frames)\")\n",
    "ax.legend(loc='lower right', frameon=True)\n",
    "txt = f\"Spearman ρ = {rho_p95:.2f}\"\n",
    "if not np.isnan(p_p95): txt += f\" (p={p_p95:.3g})\"\n",
    "ax.text(0.02, 0.05, txt, transform=ax.transAxes)\n",
    "fig.tight_layout()\n",
    "scatter_path = FIGS_DIR / \"dic_vs_pbar_scatter.png\"\n",
    "fig.savefig(scatter_path, dpi=200)\n",
    "plt.close(fig)\n",
    "print(\"Saved:\", scatter_path)\n",
    "\n",
    "# 2) Coverage by quartiles of p95_disp\n",
    "\n",
    "\n",
    "# (A) Quartile coverage bar with counts; FutureWarning fixed via observed=True\n",
    "q4 = pd.qcut(dfj_haze[\"p95_disp_px\"], q=4)\n",
    "def _short(iv): return f\"{iv.left:.2f}–{iv.right:.2f}\"\n",
    "q4 = q4.cat.rename_categories([_short(iv) for iv in q4.cat.categories])\n",
    "\n",
    "cov_by_bin = (\n",
    "    dfj_haze.assign(bin=q4)\n",
    "            .groupby(\"bin\", observed=True)  # <- fixes the warning\n",
    "            .agg(coverage=(\"pbar\", lambda s: float((s >= THR).mean())),\n",
    "                 n=(\"pbar\",\"size\"))\n",
    "            .reset_index()\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "ax.bar(cov_by_bin[\"bin\"], cov_by_bin[\"coverage\"])\n",
    "for i,(c,n) in enumerate(zip(cov_by_bin[\"coverage\"], cov_by_bin[\"n\"])):\n",
    "    ax.text(i, c+0.02, f\"n={n}\", ha=\"center\", va=\"bottom\", fontsize=9)\n",
    "ax.set_ylim(0,1.05)\n",
    "ax.set_xlabel(\"Quartile of per-frame displacement (p95, pixels)\")\n",
    "ax.set_ylabel(\"Coverage at T (fraction ≥ T)\")\n",
    "ax.set_title(\"Coverage by DIC displacement quartile\")\n",
    "fig.tight_layout()\n",
    "fig.savefig(FIGS_DIR/\"coverage_by_p95_quartile.png\", dpi=200)\n",
    "plt.close(fig)\n",
    "\n",
    "# (B) Decile-binned median ± IQR of classifier score vs p95\n",
    "q10 = pd.qcut(dfj_haze[\"p95_disp_px\"], q=10, duplicates=\"drop\")\n",
    "q10 = q10.cat.rename_categories([_short(iv) for iv in q10.cat.categories])\n",
    "\n",
    "summ10 = (\n",
    "    dfj_haze.assign(bin=q10)\n",
    "            .groupby(\"bin\", observed=True)\n",
    "            .agg(median=(\"pbar\",\"median\"),\n",
    "                 q25=(\"pbar\", lambda s: float(np.percentile(s,25))),\n",
    "                 q75=(\"pbar\", lambda s: float(np.percentile(s,75))),\n",
    "                 cover=(\"pbar\", lambda s: float((s>=THR).mean())),\n",
    "                 n=(\"pbar\",\"size\"))\n",
    "            .reset_index()\n",
    ")\n",
    "\n",
    "x = np.arange(len(summ10))\n",
    "y = summ10[\"median\"].to_numpy()\n",
    "yerr = np.vstack([y - summ10[\"q25\"].to_numpy(),\n",
    "                  summ10[\"q75\"].to_numpy() - y])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(9,5))\n",
    "ax.errorbar(x, y, yerr=yerr, fmt=\"o-\", capsize=3, lw=1.5)\n",
    "ax.axhline(THR, ls=\"--\", lw=1.2, label=f\"Threshold T={THR:.3f}\")\n",
    "for i,(yy,cov,n) in enumerate(zip(y, summ10[\"cover\"], summ10[\"n\"])):\n",
    "    ax.text(i, yy+0.01, f\"cov={cov:.2f}\\n(n={n})\", ha=\"center\", va=\"bottom\", fontsize=8)\n",
    "ax.set_ylim(max(0.0, min(0.6, y.min()-0.05)), 1.02)\n",
    "ax.set_xlim(-0.5, len(x)-0.5)\n",
    "ax.set_xticks(x); ax.set_xticklabels(summ10[\"bin\"], rotation=45, ha=\"right\")\n",
    "ax.set_xlabel(\"DIC displacement p95 (deciles, pixels)\")\n",
    "ax.set_ylabel(\"Classifier probability (median, IQR)\")\n",
    "ax.set_title(\"Classifier score vs DIC displacement (deciles)\")\n",
    "ax.legend(loc=\"lower left\")\n",
    "fig.tight_layout()\n",
    "fig.savefig(FIGS_DIR/\"pbar_vs_dic_deciles.png\", dpi=200)\n",
    "plt.close(fig)\n",
    "\n",
    "print(\"Saved:\",\n",
    "      FIGS_DIR/\"coverage_by_p95_quartile.png\",\n",
    "      FIGS_DIR/\"pbar_vs_dic_deciles.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8631e7ab-4b49-45e4-b4b7-51766de9cfe4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
